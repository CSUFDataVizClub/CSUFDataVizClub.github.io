---
title: "Classification Continued"
author: "Taha Monfared"
date: "December 29, 2016"
output: 
  github_document:
    html_preview: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,message = FALSE)
```

```{r,echo=FALSE}
flea<-read.table("/home/taha/Comp-Stats/Rmd-files/Data/Flea.txt",header = TRUE)
```

```{r}
require(MASS)
require(MVN)
require(scales)
require(ggplot2)
require(dplyr)
source('http://www.public.iastate.edu/~maitra/stat501/Rcode/BoxMTest.R')
```

This time we're going to explore other options for classification. Namely discriminant analysis and K nearest neighbours. 

Again we prepare our data and make the test and train sets. 

```{r}
flea$type<-as.factor(flea$type)
flea$index<-1:nrow(flea)
rand<-sample(1:nrow(flea),5)
test<-flea[rand,]
train<-flea[-rand,]

X_range<-seq(min(flea$Y1),max(flea$Y1),length.out = 300)
Y_range<-seq(min(flea$Y2),max(flea$Y2),length.out = 300)
XY_grid<-expand.grid(X_range,Y_range)
XY_grid<-tbl_df(XY_grid)
names(XY_grid)<-c("Y1","Y2")
```

# Linear Discriminant Analysis

From the model selection part in the last post we know Y1 and Y2 are enough for our classifications. So let's test them for the assumptions of LDA. Namely, normality and constant covariance structure between categories of response. 

```{r}
mardiaTest(flea[,2:3],qqplot = TRUE)
```

Our selected variables seem to be multivariate normal. 

```{r}
bx_test<-BoxMTest(flea[,2:3],flea[,1])
```

The covariances are not different, so we can perform LDA on the data. That's good news, less parameters to estimate in the analysis!

let's see how does the LDA predict.

```{r}

lda_fit<-lda(data=flea,type~Y1+Y2,subset=6:39)

##to find the boundary
tmp<-data.frame(pred=predict(lda_fit)$x,Y1=flea$Y1[6:39],Y2=flea$Y2[6:39])
lm_line<-lm(data=tmp,LD1~Y1+Y2)
coef_line<-coef(lm_line)
lda_line<-function(Y1){(-coef_line[1]-coef_line[2]*Y1)/coef_line[3]}
x<-seq(min(flea$Y1),max(flea$Y1),length.out = 300)
y<-lda_line(x)
lda_pred<-data.frame(x,y)
####

ggplot()+geom_point(data=flea,aes(x=Y1,y=Y2,col=type))+theme_minimal()+
  geom_line(data=lda_pred,aes(x=x,y=y))+
  geom_text(data=flea[rand,],aes(x=Y1,y=Y2,label=index),nudge_x = 1,cex=2,col="black")
```

The boundary line is almost the same as the logistics regression boundary, with a small difference in grouping the one point on the boundary line in the right group where glm failed.

```{r}
lda.pred = predict(lda_fit, test)
lda.class =lda.pred$class
table(lda.class , test[, 1] )
cat("Misclassification rate:",percent(mean(lda.class !=  test[, 1])))

lda.pred = predict(lda_fit, train)
lda.class =lda.pred$class
table(lda.class , train[, 1] )
cat("Misclassification rate:",percent(mean(lda.class !=  train[, 1])))
```

Bayes decision boundary is calculated by equating discriminant functions of two categories. 

$\delta_k(x)=-1/2(x-\mu)^T\Sigma^{-1}(x-\mu)+log(\pi_k)$

equating two class delta functions would result in:

$x^T\Sigma^{-1}(\mu_k-\mu_j)=C$

which is basically a linear function of x. 

To visualize the boundary line we had to find the intercept (the coefficients are given by the lda function). So we ran a linear regression function to get that and made the function for the boundary line and voilÃ !

#Quadratic Discriminant Analysis

Let's perform QDA and see what are the challenges there. First off, there is no boundary function output in the predict which makes it hard to draw it... So we need to use the contour plot to visualize the probabilities assigned and the cutoff boundary mapped to the 2D plot.


```{r}
tr<-setdiff(1:nrow(flea),rand)
qda_fit<-qda(data=flea,type~Y1+Y2,subset=tr)

####finding the boundary curve by using contour plot
XY_grid$type<-as.numeric(predict(qda_fit,XY_grid)$class)
pal<-c("dodgerblue3","deepskyblue2","darkolivegreen3","darkcyan",
       "goldenrod1","darkorange","deeppink2","darkorchid","lightblue3")

plt<-ggplot(data=flea,aes(x=Y1,y=Y2,col=type))+
  geom_point()+theme_minimal()+
  geom_text(data=flea[rand,],aes(x=Y1,y=Y2,label=index),nudge_x = 1,col="black",cex=2)
plt+stat_contour(data=XY_grid,aes(x=Y1,y=Y2,z=type))+
  labs(title="QDA Boundary")

####
```

Bayes decision boundary is derived from equating each group's quadratic discriminant function $\delta_k$ to the other. 

$\delta_k=\frac{-1}{2}(x-\mu_k)^T\Sigma_k^{-1}(x-\mu_k)-1/2log(|\Sigma_k|)+log(\pi_k)$

where $\mu_k,\Sigma_k,\pi_k$ are all estimated based on the sample. The data is scaled in the qda function. Scaling is first done on the train set. Then each new point should be scaled based on mean and standard deviations calculated for the train data set. And then we can resume building our disriminant functions. 

Then the mean and covariance matrix of each category is estimated by their MLEs from the sample. 

Equating two functions will give us an ellipsoid function that looks like:

$x^T[\Sigma_k^{-1}(x-2\mu_k)-\Sigma_j^{-1}(x-2\mu_j)]=c$

It's not an easy task to draw this. So we'll stick with drawing the contour. 

I just provided functions to calculate qda posterior probabilities to see how the scaling is working in the qda function. 

```{r}
####Posterior Probabilities as calculated by qda

pi_tb<-train%>%group_by(type)%>%summarize(frq=n())%>%mutate(pi=frq/sum(frq))

tmp<-train[,2:3]
mu<-colMeans(tmp)
vars<-apply(tmp,2,sd)

sc<-train[,1:3]
sc[,2:3]<-scale(sc[,2:3])

tmp<-sc%>%filter(type=="1")
tmp<-tmp[,-1]
mu_1<-colMeans(tmp)
sol_sig_1<-solve(cov(tmp))
det_sig_1<-det(cov(tmp))

tmp<-sc%>%filter(type=="2")
tmp<-tmp[,-1]
mu_2<-colMeans(tmp)
sol_sig_2<-solve(cov(tmp))
det_sig_2<-det(cov(tmp))
  
post_1<-function(x){
  x<-as.matrix(x)
  x<-(x-mu)/vars
  exp(-1/2*matrix(x-mu_1,nrow=1)%*%sol_sig_1%*%matrix(x-mu_1,ncol=1))*
    (det_sig_1)^(-1/2)*(pi_tb$pi[1])
}

post_2<-function(x){
  x<-as.matrix(x)
  x<-(x-mu)/vars
  exp(-1/2*matrix(x-mu_2,nrow=1)%*%sol_sig_2%*%matrix(x-mu_2,ncol=1))*
    (det_sig_2)^(-1/2)*(pi_tb$pi[2])
}

posterior<-function(x){
  p<-numeric(2)
  p[1]<-post_1(x)
  p[2]<-post_2(x)
  p<-p/sum(p)
  return(p)
}

posterior(x=train[1,2:3])
predict(qda_fit)$posterior[1,]
#####
```

Now let's check the errors.

```{r}
qda_pred = predict(qda_fit, test)
qda_class =qda_pred$class
table(qda_class , test[, 1] )
cat("Misclassification rate:",percent(mean(qda_class !=  test[, 1])))

qda_pred = predict(qda_fit, train)
qda_class =qda_pred$class
table(qda_class , train[, 1] )
cat("Misclassification rate:",percent(mean(qda_class !=  train[, 1])))

```

Note: In such small dataset with MVN test showing the data is normal, we prefer LDA to QDA. 

# K Nearest Neighbours

KNN is in the class package.

```{r}
require(class)

knn3<-knn(train[,2:3],test[,2:3],cl =train[,1],k = 3,prob = TRUE )
table(knn3 , test[, 1] )
cat("Misclassification rate:",percent(mean(knn3 !=  test[, 1])))

knn3<-knn(train[,2:3],train[,2:3],cl =train[,1],k = 3,prob = TRUE )
table(knn3 , train[, 1] )
cat("Misclassification rate (for train set):",percent(mean(knn3 !=  train[, 1])))

knn_plt<-knn(train[,2:3],XY_grid[,1:2],cl =train[,1],k = 3,prob = TRUE )
prob<-attr(knn_plt,"prob")
XY_grid$pred_knn<-ifelse(knn_plt=="1",prob,1-prob)
XY_grid$type<-ifelse(XY_grid$pred_knn<.5,1,2)

plt<-ggplot(data=flea,aes(x=Y1,y=Y2,col=type))+
  geom_point()+theme_minimal()+
  geom_text(data=flea[rand,],aes(x=Y1,y=Y2,label=index),nudge_x = 1,col="black",cex=2)
plt+stat_contour(data=XY_grid,aes(x=Y1,y=Y2,z=type))+
  labs(title="KNN,k=3 Boundary")
```

In plotting the boundary, you should consider that the _prob attribute_ output for the knn is very strange. If it is 1, we should keep it as is. If it's not 1, we should take 1-prob to be the assigned probability... nonsense!

```{r}
knn4<-knn(train[,2:3],test[,2:3],cl =train[,1],k = 4,prob = TRUE )
table(knn4 , test[, 1] )
cat("Misclassification rate:",percent(mean(knn4 !=  test[, 1])))

knn4<-knn(train[,2:3],train[,2:3],cl =train[,1],k = 4,prob = TRUE )
table(knn4 , train[, 1] )
cat("Misclassification rate (for train set):",percent(mean(knn4 !=  train[, 1])))

knn_plt<-knn(train[,2:3],XY_grid[,1:2],cl =train[,1],k = 4,prob = TRUE )
prob<-attr(knn_plt,"prob")
XY_grid$pred_knn<-ifelse(knn_plt=="1",prob,1-prob)
XY_grid$type<-ifelse(XY_grid$pred_knn<.5,1,2)

plt<-ggplot(data=flea,aes(x=Y1,y=Y2,col=type))+
  geom_point()+theme_minimal()+
  geom_text(data=flea[rand,],aes(x=Y1,y=Y2,label=index),nudge_x = 1,col="black",cex=2)
plt+stat_contour(data=XY_grid,aes(x=Y1,y=Y2,z=type))+
  labs(title="KNN,k=4 Boundary")

```


```{r}
knn5<-knn(train[,2:3],test[,2:3],cl =train[,1],k = 5,prob = TRUE )
table(knn5 , test[, 1] )
cat("Misclassification rate:",percent(mean(knn5 !=  test[, 1])))

knn5<-knn(train[,2:3],train[,2:3],cl =train[,1],k = 5,prob = TRUE )
table(knn5 , train[, 1] )
cat("Misclassification rate (for train set):",percent(mean(knn5 !=  train[, 1])))

knn_plt<-knn(train[,2:3],XY_grid[,1:2],cl =train[,1],k = 5,prob = TRUE )
prob<-attr(knn_plt,"prob")
XY_grid$pred_knn<-ifelse(knn_plt=="1",prob,1-prob)
XY_grid$type<-ifelse(XY_grid$pred_knn<.5,1,2)

plt<-ggplot(data=flea,aes(x=Y1,y=Y2,col=type))+
  geom_point()+theme_minimal()+
  geom_text(data=flea[rand,],aes(x=Y1,y=Y2,label=index),nudge_x = 1,col="black",cex=2)
plt+stat_contour(data=XY_grid,aes(x=Y1,y=Y2,z=type))+
  labs(title="KNN,k=5 Boundary")
```

The boundaries produced by the KNN are mental... since this was not a complex dataset and the LDA assumptions were met, we don't need such highly volatile estimates for our boundaries. But this could become handy when we have a harsher dataset to analyse.  

Every classifier we discussed here produced really good classification. Although this was in part because of wise variable selection, and in part because of the distance between two categories.
